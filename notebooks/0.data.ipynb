{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSWEduChat Translations & Post-Edited Data Processing\n",
    "\n",
    "This notebook performs the following steps:\n",
    "1. **Importing Libraries & Reading Data:**  \n",
    "   It imports necessary libraries and reads two Excel files containing translation data and post-edited texts.\n",
    "   \n",
    "2. **Extracting & Saving Translations:**  \n",
    "   It extracts translation columns from the Excel sheets, creates a combined DataFrame, and writes individual language translations as text files. In addition, a complete CSV file of all translations is created.\n",
    "   \n",
    "3. **Processing Post-Edited Data:**  \n",
    "   The notebook reads a second Excel file (with sentence-level and paragraph-level texts) and separates sheets based on whether they contain “sentence” or “paragraph” data.  \n",
    "   For each sheet, it:\n",
    "   - Flags rows that contain the word \"Translation\" (or empty strings) in the `Original` column.\n",
    "   - Selects only those rows that are not flagged.\n",
    "   - Extracts the `Generated` (original) and `Corrected` (post-edited) texts.\n",
    "   - Drops any missing values and resets the index.\n",
    "   - Saves the processed data to CSV files in separate directories for paragraphs and sentences.\n",
    "   - Finally, a JSON file is written listing all processed language names for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets_dict = pd.read_excel(\n",
    "    \"../data/NSWEduChat_all languages_60 translations[100].xlsx\",\n",
    "    engine=\"openpyxl\",\n",
    "    sheet_name=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"english\"] = sheets_dict[\"Arabic\"][\"English paragraph\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in sheets_dict.keys():\n",
    "    data[lang.lower()] = sheets_dict[lang][\"NSWEduChat translation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in data.columns:\n",
    "    data[lang].to_csv(\n",
    "        f\"../data/educhat-translation/{lang.lower()}.txt\", index=False, header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../data/educhat-translation/all_translations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Post-Edited Data\n",
    "\n",
    "In the next section, we process a second Excel file that contains both sentence-level and paragraph-level data along with their post-edited versions.\n",
    "\n",
    "- **Sheet Separation:**  \n",
    "  We read the Excel file and then separate the sheet names based on whether they end with \"sentence\" or \"paragraph\".\n",
    "\n",
    "- **Post-Editing Processing:**  \n",
    "  For each sheet, we:\n",
    "  - Create a flag to mark rows where the `Original` column either contains the word \"Translation\" or is empty.\n",
    "  - Filter out these flagged rows.\n",
    "  - Extract the `Generated` (from the `Original` column) and `Corrected` (from the `MNSW_post-edited` column) texts.\n",
    "  - Drop missing values and reset the index.\n",
    "  - Write the cleaned data to CSV files in appropriate directories.\n",
    "  - Collect the language names processed and save them to JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>MNSW_post-edited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Translation 1</td>\n",
       "      <td>Translation 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nعزيزي أولياء الأمور/الوصيين، أتمنى أن تكونوا...</td>\n",
       "      <td>\\nأعزائي الأهل/أولياء الأمور،\\nأتمنى أن تكونوا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Translation 2</td>\n",
       "      <td>Translation 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n نحن متحمسون للإعلان أن فرقة الرقص الموهوبة ...</td>\n",
       "      <td>\\n يسرنا الإعلان عن  أن فرقة الرقص الموهوبة لد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Translation 3</td>\n",
       "      <td>Translation 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n العنصر 25 أولياء الأمور والأوصياء الأعزاء، ...</td>\n",
       "      <td>\\nأعزائي الأهل وأولياء الأمور، \\nيسعدنا جداً أ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Translation 4</td>\n",
       "      <td>Translation 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n البند 33 التحيات: مرحبا، أهلاً، هيا، صباح ا...</td>\n",
       "      <td>\\nالتحيات: مرحباً، مرحباً، مرحباً، صباح الخير،...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Translation 5</td>\n",
       "      <td>Translation 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n الطفل 1: مرحبًا، أنا ليلي. ما اسمك؟ الطفل 2...</td>\n",
       "      <td>\\n الطفلة الأول: مرحبًا، أنا ليلي. ما اسمك؟ ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Translation 6</td>\n",
       "      <td>Translation 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\n العنوان: استكشاف صوت 'oo'. تتماشى هذه الدرس...</td>\n",
       "      <td>\\n عنوان الدرس: استكشاف صوت 'oo'. يتوافق درس ا...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Original  \\\n",
       "0                                       Translation 1   \n",
       "1   \\nعزيزي أولياء الأمور/الوصيين، أتمنى أن تكونوا...   \n",
       "2                                       Translation 2   \n",
       "3   \\n نحن متحمسون للإعلان أن فرقة الرقص الموهوبة ...   \n",
       "4                                       Translation 3   \n",
       "5   \\n العنصر 25 أولياء الأمور والأوصياء الأعزاء، ...   \n",
       "6                                       Translation 4   \n",
       "7   \\n البند 33 التحيات: مرحبا، أهلاً، هيا، صباح ا...   \n",
       "8                                       Translation 5   \n",
       "9   \\n الطفل 1: مرحبًا، أنا ليلي. ما اسمك؟ الطفل 2...   \n",
       "10                                      Translation 6   \n",
       "11  \\n العنوان: استكشاف صوت 'oo'. تتماشى هذه الدرس...   \n",
       "\n",
       "                                     MNSW_post-edited  \n",
       "0                                       Translation 1  \n",
       "1   \\nأعزائي الأهل/أولياء الأمور،\\nأتمنى أن تكونوا...  \n",
       "2                                       Translation 2  \n",
       "3   \\n يسرنا الإعلان عن  أن فرقة الرقص الموهوبة لد...  \n",
       "4                                       Translation 3  \n",
       "5   \\nأعزائي الأهل وأولياء الأمور، \\nيسعدنا جداً أ...  \n",
       "6                                       Translation 4  \n",
       "7   \\nالتحيات: مرحباً، مرحباً، مرحباً، صباح الخير،...  \n",
       "8                                       Translation 5  \n",
       "9   \\n الطفلة الأول: مرحبًا، أنا ليلي. ما اسمك؟ ال...  \n",
       "10                                      Translation 6  \n",
       "11  \\n عنوان الدرس: استكشاف صوت 'oo'. يتوافق درس ا...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheets_dict = pd.read_excel(\n",
    "    \"../data/Languages_by_sentence and paragraph.xlsx\",\n",
    "    engine=\"openpyxl\",\n",
    "    sheet_name=None,\n",
    ")\n",
    "\n",
    "sheets_dict[\"Arabic_full paragraph\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arabic_full paragraph',\n",
       " 'Bengali_full paragraph',\n",
       " 'Burmese_full paragraph',\n",
       " 'Cantonese_full paragraph',\n",
       " 'Hindi_full paragraph',\n",
       " 'Indonesian_full paragraph',\n",
       " 'Japanese_full paragraph',\n",
       " 'Khmer_full paragraph',\n",
       " 'Mandarin_full paragraph',\n",
       " 'Mongolian_full paragraph',\n",
       " 'Nepali_full paragraph',\n",
       " 'Persian_full paragraph',\n",
       " 'Portuguese_full paragraph',\n",
       " 'Punjabi_full paragraph',\n",
       " 'Spanish_full paragraph',\n",
       " 'Swahili_full paragraph',\n",
       " 'Tagalog_full paragraph',\n",
       " 'Tamil_full paragraph',\n",
       " 'Thai_full paragraph',\n",
       " 'Turkish_full paragraph',\n",
       " 'Urdu_full paragraph',\n",
       " 'Vietnamese_full paragraph']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [key for key in sheets_dict.keys() if key.split()[-1] == \"sentence\"]\n",
    "paragraphs = [key for key in sheets_dict.keys() if key.split()[-1] == \"paragraph\"]\n",
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_langs = []\n",
    "\n",
    "for lang in paragraphs:\n",
    "    entry = dict()\n",
    "    data = pd.DataFrame()\n",
    "    sheets_dict[lang][\"flag\"] = sheets_dict[lang][\"Original\"].apply(\n",
    "        lambda x: (\n",
    "            \"Translation\" in x.split() or len(x.strip().split()) == 0\n",
    "            if isinstance(x, str)\n",
    "            else False\n",
    "        )\n",
    "    )\n",
    "    data[\"Generated\"] = sheets_dict[lang][\"Original\"].loc[~sheets_dict[lang][\"flag\"]]\n",
    "    data[\"Corrected\"] = sheets_dict[lang][\"MNSW_post-edited\"].loc[\n",
    "        ~sheets_dict[lang][\"flag\"]\n",
    "    ]\n",
    "    data = data.dropna()\n",
    "    data = data.reset_index(drop=True)\n",
    "    data.to_csv(\n",
    "        f\"../data/post-edited/paragraph/{lang.replace('_', ' ').split()[0].lower()}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    par_langs.append(lang.replace(\"_\", \" \").split()[0].lower())\n",
    "\n",
    "\n",
    "with open(\"../data/post-edited/paragraph.json\", \"w\") as json_file:\n",
    "    json.dump(par_langs, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_langs = []\n",
    "\n",
    "for lang in sentences:\n",
    "    data = pd.DataFrame()\n",
    "    sheets_dict[lang][\"flag\"] = sheets_dict[lang][\"Original\"].apply(\n",
    "        lambda x: (\n",
    "            \"Translation\" in x.split() or len(x.strip().split()) == 0\n",
    "            if isinstance(x, str)\n",
    "            else False\n",
    "        )\n",
    "    )\n",
    "    data[\"Generated\"] = sheets_dict[lang][\"Original\"].loc[~sheets_dict[lang][\"flag\"]]\n",
    "    data[\"Corrected\"] = sheets_dict[lang][\"MNSW_post-edited\"].loc[\n",
    "        ~sheets_dict[lang][\"flag\"]\n",
    "    ]\n",
    "    data = data.dropna()\n",
    "    data = data.reset_index(drop=True)\n",
    "    data.to_csv(\n",
    "        f\"../data/post-edited/sentence/{lang.replace('_', ' ').split()[0].lower()}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    sent_langs.append(lang.replace(\"_\", \" \").split()[0].lower())\n",
    "\n",
    "with open(\"../data/post-edited/sentence.json\", \"w\") as json_file:\n",
    "    json.dump(sent_langs, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
