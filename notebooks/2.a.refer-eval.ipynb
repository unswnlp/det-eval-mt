{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation Quality Evaluation Notebook\n",
    "\n",
    "This notebook performs the following tasks:\n",
    "- **Import and Setup:** Loads necessary libraries including Pandas, JSON, evaluation metrics (BLEU, ROUGE, CHRF) and helper libraries.\n",
    "- **Metric Loading:** Loads the evaluation metric modules using the `evaluate` library.\n",
    "- **Sentence-Level Evaluation:** Reads a JSON file listing the languages, iterates over each language’s CSV file containing sentence-level translations, computes evaluation metrics (BLEU, ROUGE, CHRF) and edit distance, and stores the results in a DataFrame.\n",
    "- **Paragraph-Level Evaluation:** Similar to the sentence-level evaluation, this section reads paragraph-level translations along with additional type information. It computes the same metrics and aggregates the results by translation type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import evaluate\n",
    "import editdistance\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Evaluation Metrics\n",
    "\n",
    "The following code loads the BLEU, ROUGE, and CHRF evaluation metrics using the `evaluate` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "chrf = evaluate.load(\"chrf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-Level Evaluation\n",
    "\n",
    "This section reads a JSON file (`sentence.json`) which contains a list of language codes. For each language, the notebook reads the corresponding CSV file containing the generated and corrected sentences. It then computes the following metrics for each sentence:\n",
    "- **BLEU Score**\n",
    "- **ROUGE Scores (rouge1, rouge2, rougeL)**\n",
    "- **CHRF Score** (normalized by dividing by 100)\n",
    "- **Edit Distance** between the generated and corrected sentences\n",
    "\n",
    "A mean score is also computed across all these metrics. The results are stored in a DataFrame called `sentence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:06<00:00,  3.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>chrf</th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>edit</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arabic</td>\n",
       "      <td>0.667464</td>\n",
       "      <td>0.427287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>0.218950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arabic</td>\n",
       "      <td>0.643322</td>\n",
       "      <td>0.542066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.237078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arabic</td>\n",
       "      <td>0.804230</td>\n",
       "      <td>0.702850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.301416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arabic</td>\n",
       "      <td>0.648618</td>\n",
       "      <td>0.547669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.239257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arabic</td>\n",
       "      <td>0.880614</td>\n",
       "      <td>0.744373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.324998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>vietnamese</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>vietnamese</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>vietnamese</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>vietnamese</td>\n",
       "      <td>0.706095</td>\n",
       "      <td>0.675092</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>28</td>\n",
       "      <td>0.721398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>vietnamese</td>\n",
       "      <td>0.589666</td>\n",
       "      <td>0.505022</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>47</td>\n",
       "      <td>0.641639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1757 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        language      chrf      bleu    rouge1    rouge2    rougeL  edit  \\\n",
       "0         arabic  0.667464  0.427287  0.000000  0.000000  0.000000    17   \n",
       "1         arabic  0.643322  0.542066  0.000000  0.000000  0.000000    20   \n",
       "2         arabic  0.804230  0.702850  0.000000  0.000000  0.000000    18   \n",
       "3         arabic  0.648618  0.547669  0.000000  0.000000  0.000000    21   \n",
       "4         arabic  0.880614  0.744373  0.000000  0.000000  0.000000     9   \n",
       "...          ...       ...       ...       ...       ...       ...   ...   \n",
       "1752  vietnamese  1.000000  1.000000  1.000000  1.000000  1.000000     2   \n",
       "1753  vietnamese  1.000000  1.000000  1.000000  1.000000  1.000000     0   \n",
       "1754  vietnamese  1.000000  0.000000  1.000000  1.000000  1.000000     1   \n",
       "1755  vietnamese  0.706095  0.675092  0.779221  0.693333  0.753247    28   \n",
       "1756  vietnamese  0.589666  0.505022  0.747475  0.618557  0.747475    47   \n",
       "\n",
       "          mean  \n",
       "0     0.218950  \n",
       "1     0.237078  \n",
       "2     0.301416  \n",
       "3     0.239257  \n",
       "4     0.324998  \n",
       "...        ...  \n",
       "1752  1.000000  \n",
       "1753  1.000000  \n",
       "1754  0.800000  \n",
       "1755  0.721398  \n",
       "1756  0.641639  \n",
       "\n",
       "[1757 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/post-edited/sentence.json\", \"r\") as json_file:\n",
    "    sent_langs = json.load(json_file)\n",
    "\n",
    "entries = []    \n",
    "for lang in tqdm(sent_langs):\n",
    "    csv_file = f\"../data/post-edited/sentence/{lang}.csv\"\n",
    "    data = pd.read_csv(csv_file)\n",
    "\n",
    "    try:\n",
    "        for i in range(len(data)):\n",
    "            entry = dict()\n",
    "            # Compute evaluation scores for the given sentence.\n",
    "            bleu_score = bleu.compute(predictions=[data.iloc[i][\"Generated\"]], references=[data.iloc[i][\"Corrected\"]])\n",
    "            rouge_score = rouge.compute(predictions=[data.iloc[i][\"Generated\"]], references=[data.iloc[i][\"Corrected\"]])\n",
    "            chrf_score = chrf.compute(predictions=[data.iloc[i][\"Generated\"]], references=[data.iloc[i][\"Corrected\"]])\n",
    "            \n",
    "            # Process language name and store computed scores.\n",
    "            entry[\"language\"] = lang.replace('_', ' ').split()[0].lower()\n",
    "            entry[\"chrf\"] = chrf_score['score'] / 100\n",
    "            entry[\"bleu\"] = bleu_score['bleu']\n",
    "            entry[\"rouge1\"] = rouge_score['rouge1']\n",
    "            entry[\"rouge2\"] = rouge_score['rouge2']\n",
    "            entry[\"rougeL\"] = rouge_score['rougeL']\n",
    "            entry[\"edit\"] = editdistance.eval(data.iloc[i][\"Generated\"], data.iloc[i][\"Corrected\"])\n",
    "            # Mean score across all metrics\n",
    "            entry[\"mean\"] = (chrf_score[\"score\"]/100 + bleu_score[\"bleu\"] + \n",
    "                             rouge_score[\"rouge1\"] + rouge_score[\"rouge2\"] + rouge_score[\"rougeL\"]) / 5\n",
    "            entries.append(entry)\n",
    "    except Exception as e:\n",
    "        # Optionally log the error and continue with the next file\n",
    "        print(f\"Error processing {lang}: {e}\")\n",
    "    \n",
    "sentence = pd.DataFrame(entries)\n",
    "sentence  # Display the sentence-level evaluation DataFrame\n",
    "# Optionally, save the results:\n",
    "# sentence.to_json(\"../results/sentence.json\", orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paragraph-Level Evaluation\n",
    "\n",
    "Similar to the sentence-level evaluation, this section processes paragraph-level translations. In addition to computing the same evaluation metrics, it also reads a `types.csv` file to associate each paragraph with a specific type (e.g., circular, conversation, email, lessons, misc).\n",
    "\n",
    "Each paragraph’s metrics are computed and stored in the DataFrame `paragraph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:05<00:00,  3.78it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/post-edited/paragraph.json\", \"r\") as json_file:\n",
    "    par_langs = json.load(json_file)\n",
    "\n",
    "entries = []    \n",
    "for lang in tqdm(par_langs):\n",
    "    csv_file = f\"../data/post-edited/paragraph/{lang}.csv\"\n",
    "    data = pd.read_csv(csv_file)\n",
    "    types = pd.read_csv(\"../data/post-edited/types.csv\")\n",
    "    try:\n",
    "        for i in range(len(data)):\n",
    "            entry = dict()\n",
    "            bleu_score = bleu.compute(predictions=[data.iloc[i][\"Generated\"]], references=[data.iloc[i][\"Corrected\"]])\n",
    "            rouge_score = rouge.compute(predictions=[data.iloc[i][\"Generated\"]], references=[data.iloc[i][\"Corrected\"]])\n",
    "            chrf_score = chrf.compute(predictions=[data.iloc[i][\"Generated\"]], references=[data.iloc[i][\"Corrected\"]])\n",
    "            \n",
    "            entry[\"language\"] = lang.replace('_', ' ').split()[0].lower()\n",
    "            entry[\"chrf\"] = chrf_score['score'] / 100\n",
    "            entry[\"bleu\"] = bleu_score['bleu']\n",
    "            entry[\"rouge1\"] = rouge_score['rouge1']\n",
    "            entry[\"rouge2\"] = rouge_score['rouge2']\n",
    "            entry[\"rougeL\"] = rouge_score['rougeL']\n",
    "            entry[\"edit\"] = editdistance.eval(data.iloc[i][\"Generated\"], data.iloc[i][\"Corrected\"])\n",
    "            entry[\"mean\"] = (chrf_score[\"score\"]/100 + bleu_score[\"bleu\"] + \n",
    "                             rouge_score[\"rouge1\"] + rouge_score[\"rouge2\"] + rouge_score[\"rougeL\"]) / 5\n",
    "            # Associate the translation type\n",
    "            entry[\"type\"] = types[\"type\"].iloc[i]\n",
    "            entries.append(entry)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {lang}: {e}\")\n",
    "    \n",
    "paragraph = pd.DataFrame(entries)\n",
    "# Optionally, save the paragraph-level evaluation results:\n",
    "# paragraph.to_json(\"../results/paragraph.json\", orient=\"records\", indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
