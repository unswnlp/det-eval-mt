{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation Quality Evaluation Notebook\n",
    "\n",
    "This notebook performs the following tasks:\n",
    "- **Import and Setup:** Loads necessary libraries including Pandas, JSON, evaluation metrics (BLEU, ROUGE, CHRF) and helper libraries.\n",
    "- **Metric Loading:** Loads the evaluation metric modules using the `evaluate` library.\n",
    "- **Paragraph-Level Evaluation:** Similar to the sentence-level evaluation, this section reads paragraph-level translations along with additional type information. It computes the same metrics and aggregates the results by translation type.\n",
    "- **Sentence-Level Evaluation:** Reads a JSON file listing the languages, iterates over each language’s CSV file containing sentence-level translations, computes evaluation metrics (BLEU, ROUGE, CHRF) and edit distance, and stores the results in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import evaluate\n",
    "import editdistance\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Evaluation Metrics\n",
    "\n",
    "The following code loads the BLEU, ROUGE, and CHRF evaluation metrics using the `evaluate` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "chrf = evaluate.load(\"chrf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paragraph-Level Evaluation\n",
    "\n",
    "Similar to the sentence-level evaluation, this section processes paragraph-level translations. For each language, the notebook reads the corresponding CSV file containing the generated and corrected sentences. It then computes the following metrics for each sentence:\n",
    "- **BLEU Score**\n",
    "- **ROUGE Scores (rouge1, rouge2, rougeL)**\n",
    "- **CHRF Score** (normalized by dividing by 100)\n",
    "\n",
    "Each paragraph’s metrics are computed and stored in the DataFrame `paragraph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 20/22 [00:01<00:00, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing tamil from ../data/post-edited/paragraph/tamil.csv: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 12.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>chrf</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indonesian</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>turkish</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tagalog</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>portuguese</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spanish</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vietnamese</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>swahili</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cantonese</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hindi</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mandarin</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>thai</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>urdu</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mongolian</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>arabic</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>punjabi</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bengali</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>persian</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nepali</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>burmese</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>khmer</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      language  bleu rouge1 rouge2 rougeL  chrf  mean\n",
       "0   indonesian  0.86   0.93   0.85   0.91  0.93  0.89\n",
       "1      turkish  0.79   0.92   0.85   0.91  0.90  0.87\n",
       "2      tagalog  0.75   0.86   0.73   0.84  0.86  0.81\n",
       "3   portuguese  0.73   0.85   0.74   0.83  0.85  0.80\n",
       "4      spanish  0.64   0.85   0.73   0.84  0.82  0.78\n",
       "5   vietnamese  0.66   0.85   0.75   0.81  0.76  0.77\n",
       "6      swahili  0.59   0.81   0.78   0.81  0.71  0.74\n",
       "7    cantonese  0.61   0.67   0.67   0.67  0.78  0.68\n",
       "8        hindi  0.72   0.60   0.48   0.54  0.83  0.64\n",
       "9     mandarin  0.36   0.67   0.67   0.67  0.79  0.63\n",
       "10        thai  0.37   0.64   0.62   0.64  0.78  0.61\n",
       "11    japanese  0.00   0.83   0.65   0.82  0.70  0.60\n",
       "12        urdu  0.60   0.55   0.44   0.50  0.76  0.57\n",
       "13   mongolian  0.49   0.62   0.50   0.54  0.70  0.57\n",
       "14      arabic  0.61   0.47   0.45   0.47  0.78  0.56\n",
       "15     punjabi  0.53   0.56   0.48   0.52  0.70  0.56\n",
       "16     bengali  0.76   0.17   0.17   0.17  0.88  0.43\n",
       "17     persian  0.75   0.17   0.17   0.17  0.85  0.42\n",
       "18      nepali  0.63   0.14   0.11   0.14  0.81  0.37\n",
       "19     burmese  0.17   0.38   0.27   0.37  0.58  0.36\n",
       "20       khmer  0.16   0.37   0.31   0.37  0.55  0.35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"../data/post-edited/paragraph.json\", \"r\") as json_file:\n",
    "    par_langs = json.load(json_file)\n",
    "\n",
    "entries = []\n",
    "for lang in tqdm(par_langs):\n",
    "    csv_file = f\"../data/post-edited/paragraph/{lang}.csv\"\n",
    "    data = pd.read_csv(csv_file)\n",
    "    types = pd.read_csv(\"../data/post-edited/types.csv\")\n",
    "    try:\n",
    "        # Compute BLEU score\n",
    "        bleu_score = bleu.compute(\n",
    "            predictions=list(data[\"Generated\"]),\n",
    "            references=[[i] for i in data[\"Corrected\"]],\n",
    "        )\n",
    "        # Compute ROUGE scores (rouge1, rouge2, and rougeL)\n",
    "        rouge_score = rouge.compute(\n",
    "            predictions=list(data[\"Generated\"]),\n",
    "            references=[[i] for i in data[\"Corrected\"]],\n",
    "        )\n",
    "        # Compute CHRF score\n",
    "        chrf_score = chrf.compute(\n",
    "            predictions=list(data[\"Generated\"]),\n",
    "            references=[[i] for i in data[\"Corrected\"]],\n",
    "        )\n",
    "\n",
    "        # Compute mean score as an average of normalized CHRF, BLEU, and ROUGE scores\n",
    "        mean_score = (\n",
    "            (chrf_score[\"score\"] / 100)\n",
    "            + bleu_score[\"bleu\"]\n",
    "            + rouge_score[\"rouge1\"]\n",
    "            + rouge_score[\"rouge2\"]\n",
    "            + rouge_score[\"rougeL\"]\n",
    "        ) / 5\n",
    "\n",
    "        # Build a dictionary entry for the current language\n",
    "        entry = {\n",
    "            \"language\": lang.replace(\"_\", \" \").split()[0].lower(),\n",
    "            \"bleu\": \"%.2f\" % bleu_score[\"bleu\"],\n",
    "            \"rouge1\": \"%.2f\" % rouge_score[\"rouge1\"],\n",
    "            \"rouge2\": \"%.2f\" % rouge_score[\"rouge2\"],\n",
    "            \"rougeL\": \"%.2f\" % rouge_score[\"rougeL\"],\n",
    "            \"chrf\": \"%.2f\" % (chrf_score[\"score\"] / 100),\n",
    "            \"mean\": \"%.2f\" % mean_score,\n",
    "        }\n",
    "        entries.append(entry)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {lang} from {csv_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "paragraph = (\n",
    "    pd.DataFrame(entries)\n",
    "    .sort_values(by=[\"mean\"], ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "paragraph\n",
    "# Optionally, save the paragraph-level evaluation results:\n",
    "# paragraph.to_json(\"../results/paragraph.json\", orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-Level Evaluation\n",
    "\n",
    "This section reads a JSON file (`sentence.json`) which contains a list of language codes. A mean score is also computed across all these metrics. The results are stored in a DataFrame called `sentence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 11/22 [00:00<00:00, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing korean from ../data/post-edited/sentence/korean.csv: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 15.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>chrf</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>swahili</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indonesian</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>turkish</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vietnamese</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tagalog</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>portuguese</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spanish</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cantonese</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hindi</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mandarin</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>urdu</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>thai</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>persian</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>arabic</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>punjabi</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bengali</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mongolian</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nepali</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>khmer</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>burmese</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      language  bleu rouge1 rouge2 rougeL  chrf  mean\n",
       "0      swahili  0.89   0.96   0.83   0.96  0.93  0.91\n",
       "1   indonesian  0.83   0.95   0.86   0.94  0.92  0.90\n",
       "2      turkish  0.82   0.93   0.83   0.92  0.90  0.88\n",
       "3   vietnamese  0.73   0.88   0.82   0.87  0.77  0.81\n",
       "4      tagalog  0.75   0.83   0.70   0.82  0.85  0.79\n",
       "5   portuguese  0.73   0.84   0.71   0.83  0.84  0.79\n",
       "6      spanish  0.64   0.84   0.67   0.84  0.82  0.76\n",
       "7    cantonese  0.78   0.40   0.31   0.40  0.77  0.53\n",
       "8        hindi  0.70   0.40   0.16   0.39  0.82  0.50\n",
       "9     mandarin  0.71   0.36   0.16   0.36  0.70  0.46\n",
       "10        urdu  0.62   0.36   0.07   0.35  0.74  0.43\n",
       "11        thai  0.48   0.38   0.16   0.38  0.77  0.43\n",
       "12     persian  0.80   0.21   0.07   0.21  0.89  0.43\n",
       "13      arabic  0.61   0.32   0.08   0.33  0.77  0.42\n",
       "14     punjabi  0.58   0.34   0.15   0.34  0.70  0.42\n",
       "15     bengali  0.77   0.18   0.08   0.18  0.88  0.42\n",
       "16   mongolian  0.47   0.39   0.12   0.38  0.67  0.41\n",
       "17    japanese  0.00   0.40   0.23   0.40  0.66  0.34\n",
       "18      nepali  0.63   0.13   0.04   0.13  0.80  0.34\n",
       "19       khmer  0.23   0.21   0.10   0.21  0.53  0.26\n",
       "20     burmese  0.20   0.21   0.11   0.21  0.55  0.26"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/post-edited/sentence.json\", \"r\") as json_file:\n",
    "    sent_langs = json.load(json_file)\n",
    "\n",
    "entries = []\n",
    "for lang in tqdm(sent_langs):\n",
    "    csv_file = f\"../data/post-edited/sentence/{lang}.csv\"\n",
    "    data = pd.read_csv(csv_file)\n",
    "\n",
    "    try:\n",
    "        # Compute BLEU score\n",
    "        bleu_score = bleu.compute(\n",
    "            predictions=list(data[\"Generated\"]),\n",
    "            references=[[i] for i in data[\"Corrected\"]],\n",
    "        )\n",
    "        # Compute ROUGE scores (rouge1, rouge2, and rougeL)\n",
    "        rouge_score = rouge.compute(\n",
    "            predictions=list(data[\"Generated\"]),\n",
    "            references=[[i] for i in data[\"Corrected\"]],\n",
    "        )\n",
    "        # Compute CHRF score\n",
    "        chrf_score = chrf.compute(\n",
    "            predictions=list(data[\"Generated\"]),\n",
    "            references=[[i] for i in data[\"Corrected\"]],\n",
    "        )\n",
    "\n",
    "        # Compute mean score as an average of normalized CHRF, BLEU, and ROUGE scores\n",
    "        mean_score = (\n",
    "            (chrf_score[\"score\"] / 100)\n",
    "            + bleu_score[\"bleu\"]\n",
    "            + rouge_score[\"rouge1\"]\n",
    "            + rouge_score[\"rouge2\"]\n",
    "            + rouge_score[\"rougeL\"]\n",
    "        ) / 5\n",
    "\n",
    "        # Build a dictionary entry for the current language\n",
    "        entry = {\n",
    "            \"language\": lang.replace(\"_\", \" \").split()[0].lower(),\n",
    "            \"bleu\": \"%.2f\" % bleu_score[\"bleu\"],\n",
    "            \"rouge1\": \"%.2f\" % rouge_score[\"rouge1\"],\n",
    "            \"rouge2\": \"%.2f\" % rouge_score[\"rouge2\"],\n",
    "            \"rougeL\": \"%.2f\" % rouge_score[\"rougeL\"],\n",
    "            \"chrf\": \"%.2f\" % (chrf_score[\"score\"] / 100),\n",
    "            \"mean\": \"%.2f\" % mean_score,\n",
    "        }\n",
    "        entries.append(entry)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {lang} from {csv_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "sentence = (\n",
    "    pd.DataFrame(entries)\n",
    "    .sort_values(by=[\"mean\"], ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "sentence  # Display the sentence-level evaluation DataFrame\n",
    "# Optionally, save the results:\n",
    "# sentence.to_json(\"../results/sentence.json\", orient=\"records\", indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
