{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame:\n",
      "      Language  chrF_sent  BLEU_sent  ROUGE-1_sent  ROUGE-2_sent  \\\n",
      "0   Indonesian       0.93       0.85          0.92          0.85   \n",
      "1      Turkish       0.90       0.79          0.92          0.85   \n",
      "2      Tagalog       0.86       0.75          0.86          0.74   \n",
      "3   Portuguese       0.85       0.73          0.85          0.74   \n",
      "4      Spanish       0.82       0.64          0.84          0.73   \n",
      "5   Vietnamese       0.76       0.66          0.84          0.75   \n",
      "6      Swahili       0.71       0.58          0.81          0.78   \n",
      "7    Cantonese       0.78       0.60          0.66          0.67   \n",
      "8        Hindi       0.83       0.72          0.60          0.48   \n",
      "9     Mandarin       0.79       0.35          0.66          0.67   \n",
      "10        Thai       0.78       0.36          0.64          0.63   \n",
      "11    Japanese       0.70       0.00          0.83          0.65   \n",
      "12        Urdu       0.76       0.60          0.55          0.44   \n",
      "13   Mongolian       0.70       0.49          0.62          0.50   \n",
      "14      Arabic       0.78       0.60          0.47          0.45   \n",
      "15     Punjabi       0.70       0.53          0.56          0.48   \n",
      "16     Bengali       0.88       0.76          0.16          0.16   \n",
      "17     Persian       0.85       0.74          0.16          0.16   \n",
      "18      Nepali       0.81       0.63          0.14          0.11   \n",
      "19     Burmese       0.58       0.17          0.38          0.27   \n",
      "20       Khmer       0.55       0.16          0.36          0.31   \n",
      "\n",
      "    ROUGE-L_sent  Mean_sent  chrF_para  BLEU_para  ROUGE-1_para  ROUGE-2_para  \\\n",
      "0           0.91       0.89       0.92       0.83          0.94          0.86   \n",
      "1           0.91       0.87       0.89       0.81          0.92          0.83   \n",
      "2           0.84       0.81       0.85       0.74          0.83          0.70   \n",
      "3           0.84       0.80       0.84       0.72          0.83          0.71   \n",
      "4           0.84       0.77       0.82       0.63          0.84          0.66   \n",
      "5           0.81       0.76       0.77       0.73          0.87          0.82   \n",
      "6           0.81       0.74       0.93       0.88          0.95          0.83   \n",
      "7           0.67       0.68       0.77       0.78          0.40          0.31   \n",
      "8           0.55       0.64       0.82       0.69          0.40          0.17   \n",
      "9           0.67       0.63       0.70       0.71          0.35          0.16   \n",
      "10          0.64       0.61       0.77       0.47          0.38          0.16   \n",
      "11          0.82       0.60       0.66       0.00          0.40          0.23   \n",
      "12          0.50       0.57       0.74       0.62          0.36          0.08   \n",
      "13          0.55       0.57       0.67       0.47          0.39          0.12   \n",
      "14          0.48       0.56       0.77       0.60          0.32          0.08   \n",
      "15          0.53       0.56       0.70       0.57          0.34          0.15   \n",
      "16          0.16       0.42       0.88       0.76          0.18          0.08   \n",
      "17          0.16       0.41       0.89       0.79          0.20          0.07   \n",
      "18          0.14       0.37       0.80       0.63          0.12          0.04   \n",
      "19          0.37       0.35       0.55       0.20          0.21          0.11   \n",
      "20          0.37       0.35       0.53       0.23          0.21          0.09   \n",
      "\n",
      "    ROUGE-L_para  Mean_para  \n",
      "0           0.94       0.90  \n",
      "1           0.92       0.87  \n",
      "2           0.82       0.79  \n",
      "3           0.83       0.79  \n",
      "4           0.84       0.76  \n",
      "5           0.87       0.81  \n",
      "6           0.95       0.91  \n",
      "7           0.40       0.53  \n",
      "8           0.39       0.49  \n",
      "9           0.35       0.45  \n",
      "10          0.39       0.43  \n",
      "11          0.39       0.34  \n",
      "12          0.35       0.43  \n",
      "13          0.38       0.41  \n",
      "14          0.33       0.42  \n",
      "15          0.33       0.42  \n",
      "16          0.18       0.42  \n",
      "17          0.21       0.43  \n",
      "18          0.12       0.34  \n",
      "19          0.21       0.26  \n",
      "20          0.21       0.25  \n",
      "\n",
      "Pearson Correlation Coefficients:\n",
      "chrF    : r = 0.861, p-value = 5.364e-07\n",
      "BLEU    : r = 0.895, p-value = 4.539e-08\n",
      "ROUGE-1 : r = 0.868, p-value = 3.420e-07\n",
      "ROUGE-2 : r = 0.816, p-value = 6.349e-06\n",
      "ROUGE-L : r = 0.868, p-value = 3.451e-07\n",
      "Mean    : r = 0.898, p-value = 3.315e-08\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "data_sentence = {\n",
    "    \"Language\": [\n",
    "        \"Indonesian\", \"Turkish\", \"Tagalog\", \"Portuguese\", \"Spanish\", \"Vietnamese\",\n",
    "        \"Swahili\", \"Cantonese\", \"Hindi\", \"Mandarin\", \"Thai\", \"Japanese\",\n",
    "        \"Urdu\", \"Mongolian\", \"Arabic\", \"Punjabi\", \"Bengali\", \"Persian\", \"Nepali\",\n",
    "        \"Burmese\", \"Khmer\"\n",
    "    ],\n",
    "    \"chrF\": [0.93, 0.90, 0.86, 0.85, 0.82, 0.76, 0.71, 0.78, 0.83, 0.79, 0.78, 0.70,\n",
    "             0.76, 0.70, 0.78, 0.70, 0.88, 0.85, 0.81, 0.58, 0.55],\n",
    "    \"BLEU\": [0.85, 0.79, 0.75, 0.73, 0.64, 0.66, 0.58, 0.60, 0.72, 0.35, 0.36, 0.00,\n",
    "             0.60, 0.49, 0.60, 0.53, 0.76, 0.74, 0.63, 0.17, 0.16],\n",
    "    \"ROUGE-1\": [0.92, 0.92, 0.86, 0.85, 0.84, 0.84, 0.81, 0.66, 0.60, 0.66, 0.64, 0.83,\n",
    "                0.55, 0.62, 0.47, 0.56, 0.16, 0.16, 0.14, 0.38, 0.36],\n",
    "    \"ROUGE-2\": [0.85, 0.85, 0.74, 0.74, 0.73, 0.75, 0.78, 0.67, 0.48, 0.67, 0.63, 0.65,\n",
    "                0.44, 0.50, 0.45, 0.48, 0.16, 0.16, 0.11, 0.27, 0.31],\n",
    "    \"ROUGE-L\": [0.91, 0.91, 0.84, 0.84, 0.84, 0.81, 0.81, 0.67, 0.55, 0.67, 0.64, 0.82,\n",
    "                0.50, 0.55, 0.48, 0.53, 0.16, 0.16, 0.14, 0.37, 0.37],\n",
    "    \"Mean\": [0.89, 0.87, 0.81, 0.80, 0.77, 0.76, 0.74, 0.68, 0.64, 0.63, 0.61, 0.60,\n",
    "             0.57, 0.57, 0.56, 0.56, 0.42, 0.41, 0.37, 0.35, 0.35]\n",
    "}\n",
    "\n",
    "\n",
    "data_paragraph = {\n",
    "    \"Language\": [\n",
    "        \"Swahili\", \"Indonesian\", \"Turkish\", \"Vietnamese\", \"Tagalog\", \"Portuguese\",\n",
    "        \"Spanish\", \"Cantonese\", \"Hindi\", \"Mandarin\", \"Persian\", \"Thai\", \"Urdu\",\n",
    "        \"Bengali\", \"Arabic\", \"Punjabi\", \"Mongolian\", \"Nepali\", \"Japanese\", \"Burmese\",\n",
    "        \"Khmer\"\n",
    "    ],\n",
    "    \"chrF\": [0.93, 0.92, 0.89, 0.77, 0.85, 0.84, 0.82, 0.77, 0.82, 0.70, 0.89, 0.77,\n",
    "             0.74, 0.88, 0.77, 0.70, 0.67, 0.80, 0.66, 0.55, 0.53],\n",
    "    \"BLEU\": [0.88, 0.83, 0.81, 0.73, 0.74, 0.72, 0.63, 0.78, 0.69, 0.71, 0.79, 0.47,\n",
    "             0.62, 0.76, 0.60, 0.57, 0.47, 0.63, 0.00, 0.20, 0.23],\n",
    "    \"ROUGE-1\": [0.95, 0.94, 0.92, 0.87, 0.83, 0.83, 0.84, 0.40, 0.40, 0.35, 0.20, 0.38,\n",
    "                0.36, 0.18, 0.32, 0.34, 0.39, 0.12, 0.40, 0.21, 0.21],\n",
    "    \"ROUGE-2\": [0.83, 0.86, 0.83, 0.82, 0.70, 0.71, 0.66, 0.31, 0.17, 0.16, 0.07, 0.16,\n",
    "                0.08, 0.08, 0.08, 0.15, 0.12, 0.04, 0.23, 0.11, 0.09],\n",
    "    \"ROUGE-L\": [0.95, 0.94, 0.92, 0.87, 0.82, 0.83, 0.84, 0.40, 0.39, 0.35, 0.21, 0.39,\n",
    "                0.35, 0.18, 0.33, 0.33, 0.38, 0.12, 0.39, 0.21, 0.21],\n",
    "    \"Mean\": [0.91, 0.90, 0.87, 0.81, 0.79, 0.79, 0.76, 0.53, 0.49, 0.45, 0.43, 0.43,\n",
    "             0.43, 0.42, 0.42, 0.42, 0.41, 0.34, 0.34, 0.26, 0.25]\n",
    "}\n",
    "\n",
    "\n",
    "df_sentence = pd.DataFrame(data_sentence)\n",
    "df_paragraph = pd.DataFrame(data_paragraph)\n",
    "\n",
    "\n",
    "merged_df = pd.merge(df_sentence, df_paragraph, on=\"Language\", suffixes=('_sent', '_para'))\n",
    "\n",
    "print(\"Merged DataFrame:\")\n",
    "print(merged_df)\n",
    "\n",
    "\n",
    "metrics = [\"chrF\", \"BLEU\", \"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\", \"Mean\"]\n",
    "\n",
    "print(\"\\nPearson Correlation Coefficients:\")\n",
    "for metric in metrics:\n",
    "    col_sent = metric + \"_sent\"\n",
    "    col_para = metric + \"_para\"\n",
    "    # Calculate Pearson correlation and p-value\n",
    "    r, p_value = pearsonr(merged_df[col_sent], merged_df[col_para])\n",
    "    print(f\"{metric:8s}: r = {r:.3f}, p-value = {p_value:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
